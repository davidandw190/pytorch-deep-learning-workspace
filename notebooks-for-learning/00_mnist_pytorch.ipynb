{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidandw190/pytorch-deep-learning-workspace/blob/main/notebooks/mnist_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0ztC_FD7glfD"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_dsdK1Wug93z",
        "outputId": "0d155feb-1358-49bb-cae0-4a32f9deb883"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load the MNIST dataset for training\n",
        "train_data = datasets.MNIST(\n",
        "    root = 'data',          # Directory where the data will be stored\n",
        "    train = True,           # Directory where the data will be stored\n",
        "    transform = ToTensor(), # Transforms the images to PyTorch tensors\n",
        "    download = True         # Downloads the dataset if not present\n",
        ")\n",
        "\n",
        "# Load the MNIST dataset for testing\n",
        "test_data = datasets.MNIST(\n",
        "    root = 'data',\n",
        "    train = False,          # Specifies that this is the test dataset\n",
        "    transform = ToTensor(),\n",
        "    download = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBIVTSmbhYKu",
        "outputId": "a0c541b4-4ef0-4327-d799-7e4a2816eb6e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_soqJSqshmQy",
        "outputId": "d26f75d7-5f92-4ccd-f9b6-aa20920b5a98"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: data\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXEJyXcA-OaL"
      },
      "source": [
        "The `train_data.data` attribute contains the raw pixel values of the images in the MNIST training dataset. When using the `datasets.MNIST` class from `torchvision`, this attribute is a `torch.Tensor` of shape (60000, 28, 28), where:\n",
        "- 60000 is the number of training images.\n",
        "- 28 is the height of each image in pixels.\n",
        "- 28 is the width of each image in pixels.\n",
        "\n",
        "\n",
        "2The `.shape` attribute of a `torch.Tensor` provides the dimensions of the tensor as a tuple. This is similar to the .shape attribute in numpy arrays. Understanding the shape of your data is crucial for ensuring that it is correctly formatted for input into neural networks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiHrtXlohowN",
        "outputId": "1ddeb81f-4aa2-4269-dbb9-8e83d58c0368"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([60000, 28, 28])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.data.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOuGdaC6_CK3"
      },
      "source": [
        "The `train_data.targets` attribute contains the labels for the images in the MNIST training dataset. Each label corresponds to the digit (0-9) that the image represents. In the case of the MNIST dataset, this attribute is a `torch.Tensor` of shape (60000,), where 60000 is the number of training images.\n",
        "\n",
        "The `.size()` method of a `torch.Tensor` returns the size of the tensor as a `torch.Size` object, which is a subclass of Python's tuple. This method is useful for quickly inspecting the dimensions of a tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49GrIErthq8g",
        "outputId": "a7e851b0-7248-4431-a805-68d5d7621645"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([60000])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.targets.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YgVG1EXViFJU"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bp853bJHiMsJ"
      },
      "outputs": [],
      "source": [
        "# Create data loaders for training and testing datasets\n",
        "loaders = {\n",
        "    'train': DataLoader(train_data,\n",
        "                        batch_size=100,  # Number of samples per batch to load\n",
        "                        shuffle=True,    # Shuffle the data at every epoch\n",
        "                        num_workers=1),  # Number of subprocesses to use\n",
        "\n",
        "    'test': DataLoader(test_data,\n",
        "                        batch_size=100,\n",
        "                        shuffle=True,\n",
        "                        num_workers=1)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJB8QGTBiY0V",
        "outputId": "3c0178bd-4854-4428-a150-02dbefc7d98c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'train': <torch.utils.data.dataloader.DataLoader at 0x7a66cae0aaa0>,\n",
              " 'test': <torch.utils.data.dataloader.DataLoader at 0x7a66cae0aa10>}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "T9nbsy0uioUi"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "class CNN(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "\n",
        "    # Convolutional layers\n",
        "    self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "    self.conv2_drop = nn.Dropout2d() # Dropout layer for regularization\n",
        "\n",
        "    # Fully connected layers\n",
        "    self.fc1 = nn.Linear(320, 50)\n",
        "    self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Apply first convolutional layer followed by ReLU activation\n",
        "    # and max pooling\n",
        "    x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "\n",
        "    # Apply second convolutional layer, dropout, followed by ReLU\n",
        "    # activation and max pooling\n",
        "    x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "\n",
        "    # Flatten the tensor to fit into fully connected layer\n",
        "    x = x.view(-1, 320)\n",
        "\n",
        "    # Apply first fully connected layer followed by ReLU activation\n",
        "    x = F.relu(self.fc1(x))\n",
        "\n",
        "    # Apply dropout during training\n",
        "    x = F.dropout(x, training=self.training)\n",
        "\n",
        "    # Apply second fully connected layer\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return F.log_softmax(x, dim=1)  # Apply log softmax on the output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "CYznHoLfi7gn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Set the device to GPU if available, otherwise CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Initialize the model and move it to the specified device\n",
        "model = CNN().to(device)\n",
        "\n",
        "# Define the optimizer, here using Adam with a learning rate of 0.001\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Define the loss function, here using CrossEntropyLoss which is suitable for multi-class classification problems\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()  # Set the model to training mode\n",
        "    for batch_idx, (data, target) in enumerate(loaders['train']):  # Corrected loader key to 'train'\n",
        "        data, target = data.to(device), target.to(device)  # Move data and target tensors to the specified device\n",
        "        optimizer.zero_grad()  # Clear the gradients\n",
        "        output = model(data)  # Forward pass\n",
        "        loss = loss_fn(output, target)  # Compute the loss\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer.step()  # Update the weights\n",
        "\n",
        "        # Print training status every 25 batches\n",
        "        if batch_idx % 25 == 0:\n",
        "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(loaders[\"train\"].dataset)} '\n",
        "                  f'({100. * batch_idx / len(loaders[\"train\"]):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
        "\n",
        "def test():\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation for evaluation\n",
        "        for data, target in loaders['test']:  # Iterate over the test data\n",
        "            data, target = data.to(device), target.to(device)  # Move data and target tensors to the specified device\n",
        "            output = model(data)  # Forward pass\n",
        "            test_loss += loss_fn(output, target).item()  # Accumulate the loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()  # Count correct predictions\n",
        "\n",
        "    test_loss /= len(loaders['test'].dataset)  # Calculate average test loss\n",
        "    accuracy = 100. * correct / len(loaders['test'].dataset)  # Calculate accuracy\n",
        "\n",
        "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(loaders[\"test\"].dataset)} '\n",
        "          f'({accuracy:.0f}%)\\n')  # Print test results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQIGSLcMC9OK",
        "outputId": "a8749b25-c325-4f51-976b-7870cffb6d91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.318525\n",
            "Train Epoch: 1 [2500/60000 (4%)]\tLoss: 2.143365\n",
            "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 1.477910\n",
            "Train Epoch: 1 [7500/60000 (12%)]\tLoss: 1.098507\n",
            "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.924714\n",
            "Train Epoch: 1 [12500/60000 (21%)]\tLoss: 0.746772\n",
            "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 0.671529\n",
            "Train Epoch: 1 [17500/60000 (29%)]\tLoss: 0.653538\n",
            "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.633377\n",
            "Train Epoch: 1 [22500/60000 (38%)]\tLoss: 0.601702\n",
            "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.398121\n",
            "Train Epoch: 1 [27500/60000 (46%)]\tLoss: 0.530805\n",
            "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.527685\n",
            "Train Epoch: 1 [32500/60000 (54%)]\tLoss: 0.484680\n",
            "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 0.304631\n",
            "Train Epoch: 1 [37500/60000 (62%)]\tLoss: 0.377491\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.468544\n",
            "Train Epoch: 1 [42500/60000 (71%)]\tLoss: 0.451001\n",
            "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.426036\n",
            "Train Epoch: 1 [47500/60000 (79%)]\tLoss: 0.306385\n",
            "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.234301\n",
            "Train Epoch: 1 [52500/60000 (88%)]\tLoss: 0.431793\n",
            "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.285506\n",
            "Train Epoch: 1 [57500/60000 (96%)]\tLoss: 0.282694\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9575/10000 (96%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.334369\n",
            "Train Epoch: 2 [2500/60000 (4%)]\tLoss: 0.341380\n",
            "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.231002\n",
            "Train Epoch: 2 [7500/60000 (12%)]\tLoss: 0.393680\n",
            "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.424493\n",
            "Train Epoch: 2 [12500/60000 (21%)]\tLoss: 0.258855\n",
            "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.450004\n",
            "Train Epoch: 2 [17500/60000 (29%)]\tLoss: 0.286660\n",
            "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.394376\n",
            "Train Epoch: 2 [22500/60000 (38%)]\tLoss: 0.457084\n",
            "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.273149\n",
            "Train Epoch: 2 [27500/60000 (46%)]\tLoss: 0.321167\n",
            "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.251104\n",
            "Train Epoch: 2 [32500/60000 (54%)]\tLoss: 0.276045\n",
            "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.373863\n",
            "Train Epoch: 2 [37500/60000 (62%)]\tLoss: 0.254343\n",
            "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.398768\n",
            "Train Epoch: 2 [42500/60000 (71%)]\tLoss: 0.230985\n",
            "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.478899\n",
            "Train Epoch: 2 [47500/60000 (79%)]\tLoss: 0.223779\n",
            "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.187793\n",
            "Train Epoch: 2 [52500/60000 (88%)]\tLoss: 0.437081\n",
            "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.196473\n",
            "Train Epoch: 2 [57500/60000 (96%)]\tLoss: 0.394382\n",
            "\n",
            "Test set: Average loss: 0.0010, Accuracy: 9690/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.369088\n",
            "Train Epoch: 3 [2500/60000 (4%)]\tLoss: 0.360213\n",
            "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 0.260277\n",
            "Train Epoch: 3 [7500/60000 (12%)]\tLoss: 0.257209\n",
            "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.196858\n",
            "Train Epoch: 3 [12500/60000 (21%)]\tLoss: 0.201326\n",
            "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.268504\n",
            "Train Epoch: 3 [17500/60000 (29%)]\tLoss: 0.283532\n",
            "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.241612\n",
            "Train Epoch: 3 [22500/60000 (38%)]\tLoss: 0.270493\n",
            "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.192753\n",
            "Train Epoch: 3 [27500/60000 (46%)]\tLoss: 0.231673\n",
            "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.302169\n",
            "Train Epoch: 3 [32500/60000 (54%)]\tLoss: 0.108438\n",
            "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 0.189355\n",
            "Train Epoch: 3 [37500/60000 (62%)]\tLoss: 0.355680\n",
            "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.339172\n",
            "Train Epoch: 3 [42500/60000 (71%)]\tLoss: 0.176491\n",
            "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 0.388787\n",
            "Train Epoch: 3 [47500/60000 (79%)]\tLoss: 0.216246\n",
            "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.179679\n",
            "Train Epoch: 3 [52500/60000 (88%)]\tLoss: 0.165922\n",
            "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 0.328336\n",
            "Train Epoch: 3 [57500/60000 (96%)]\tLoss: 0.168585\n",
            "\n",
            "Test set: Average loss: 0.0008, Accuracy: 9733/10000 (97%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.196404\n",
            "Train Epoch: 4 [2500/60000 (4%)]\tLoss: 0.225172\n",
            "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 0.217697\n",
            "Train Epoch: 4 [7500/60000 (12%)]\tLoss: 0.169713\n",
            "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.229266\n",
            "Train Epoch: 4 [12500/60000 (21%)]\tLoss: 0.191808\n",
            "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 0.293110\n",
            "Train Epoch: 4 [17500/60000 (29%)]\tLoss: 0.493191\n",
            "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.137321\n",
            "Train Epoch: 4 [22500/60000 (38%)]\tLoss: 0.177269\n",
            "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.194998\n",
            "Train Epoch: 4 [27500/60000 (46%)]\tLoss: 0.263743\n",
            "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.269326\n",
            "Train Epoch: 4 [32500/60000 (54%)]\tLoss: 0.271600\n",
            "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 0.293383\n",
            "Train Epoch: 4 [37500/60000 (62%)]\tLoss: 0.251719\n",
            "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.269912\n",
            "Train Epoch: 4 [42500/60000 (71%)]\tLoss: 0.244179\n",
            "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 0.226058\n",
            "Train Epoch: 4 [47500/60000 (79%)]\tLoss: 0.300645\n",
            "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.340333\n",
            "Train Epoch: 4 [52500/60000 (88%)]\tLoss: 0.168115\n",
            "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 0.266961\n",
            "Train Epoch: 4 [57500/60000 (96%)]\tLoss: 0.210579\n",
            "\n",
            "Test set: Average loss: 0.0007, Accuracy: 9767/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.233101\n",
            "Train Epoch: 5 [2500/60000 (4%)]\tLoss: 0.135563\n",
            "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 0.236488\n",
            "Train Epoch: 5 [7500/60000 (12%)]\tLoss: 0.188292\n",
            "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.203562\n",
            "Train Epoch: 5 [12500/60000 (21%)]\tLoss: 0.163894\n",
            "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 0.142925\n",
            "Train Epoch: 5 [17500/60000 (29%)]\tLoss: 0.177262\n",
            "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.280134\n",
            "Train Epoch: 5 [22500/60000 (38%)]\tLoss: 0.213034\n",
            "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.243314\n",
            "Train Epoch: 5 [27500/60000 (46%)]\tLoss: 0.157658\n",
            "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.218016\n",
            "Train Epoch: 5 [32500/60000 (54%)]\tLoss: 0.161593\n",
            "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 0.205589\n",
            "Train Epoch: 5 [37500/60000 (62%)]\tLoss: 0.211553\n",
            "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.148817\n",
            "Train Epoch: 5 [42500/60000 (71%)]\tLoss: 0.230624\n",
            "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 0.271719\n",
            "Train Epoch: 5 [47500/60000 (79%)]\tLoss: 0.094994\n",
            "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.147817\n",
            "Train Epoch: 5 [52500/60000 (88%)]\tLoss: 0.120586\n",
            "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 0.214986\n",
            "Train Epoch: 5 [57500/60000 (96%)]\tLoss: 0.220441\n",
            "\n",
            "Test set: Average loss: 0.0006, Accuracy: 9799/10000 (98%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.278584\n",
            "Train Epoch: 6 [2500/60000 (4%)]\tLoss: 0.110977\n",
            "Train Epoch: 6 [5000/60000 (8%)]\tLoss: 0.089053\n",
            "Train Epoch: 6 [7500/60000 (12%)]\tLoss: 0.063403\n",
            "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 0.170319\n",
            "Train Epoch: 6 [12500/60000 (21%)]\tLoss: 0.189193\n",
            "Train Epoch: 6 [15000/60000 (25%)]\tLoss: 0.249021\n",
            "Train Epoch: 6 [17500/60000 (29%)]\tLoss: 0.083379\n",
            "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 0.238479\n",
            "Train Epoch: 6 [22500/60000 (38%)]\tLoss: 0.109163\n",
            "Train Epoch: 6 [25000/60000 (42%)]\tLoss: 0.239469\n",
            "Train Epoch: 6 [27500/60000 (46%)]\tLoss: 0.242025\n",
            "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 0.211691\n",
            "Train Epoch: 6 [32500/60000 (54%)]\tLoss: 0.148411\n",
            "Train Epoch: 6 [35000/60000 (58%)]\tLoss: 0.159488\n",
            "Train Epoch: 6 [37500/60000 (62%)]\tLoss: 0.120711\n",
            "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.222314\n",
            "Train Epoch: 6 [42500/60000 (71%)]\tLoss: 0.228046\n",
            "Train Epoch: 6 [45000/60000 (75%)]\tLoss: 0.105787\n",
            "Train Epoch: 6 [47500/60000 (79%)]\tLoss: 0.157370\n",
            "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 0.098009\n",
            "Train Epoch: 6 [52500/60000 (88%)]\tLoss: 0.167174\n",
            "Train Epoch: 6 [55000/60000 (92%)]\tLoss: 0.185314\n",
            "Train Epoch: 6 [57500/60000 (96%)]\tLoss: 0.103324\n",
            "\n",
            "Test set: Average loss: 0.0006, Accuracy: 9827/10000 (98%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.196868\n",
            "Train Epoch: 7 [2500/60000 (4%)]\tLoss: 0.109601\n",
            "Train Epoch: 7 [5000/60000 (8%)]\tLoss: 0.200557\n",
            "Train Epoch: 7 [7500/60000 (12%)]\tLoss: 0.340427\n",
            "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 0.128876\n",
            "Train Epoch: 7 [12500/60000 (21%)]\tLoss: 0.306730\n",
            "Train Epoch: 7 [15000/60000 (25%)]\tLoss: 0.215303\n",
            "Train Epoch: 7 [17500/60000 (29%)]\tLoss: 0.203206\n",
            "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.251199\n",
            "Train Epoch: 7 [22500/60000 (38%)]\tLoss: 0.067469\n",
            "Train Epoch: 7 [25000/60000 (42%)]\tLoss: 0.162887\n",
            "Train Epoch: 7 [27500/60000 (46%)]\tLoss: 0.110001\n",
            "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 0.086300\n",
            "Train Epoch: 7 [32500/60000 (54%)]\tLoss: 0.151098\n",
            "Train Epoch: 7 [35000/60000 (58%)]\tLoss: 0.136026\n",
            "Train Epoch: 7 [37500/60000 (62%)]\tLoss: 0.242793\n",
            "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.378172\n",
            "Train Epoch: 7 [42500/60000 (71%)]\tLoss: 0.162217\n",
            "Train Epoch: 7 [45000/60000 (75%)]\tLoss: 0.069540\n",
            "Train Epoch: 7 [47500/60000 (79%)]\tLoss: 0.077574\n",
            "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 0.079796\n",
            "Train Epoch: 7 [52500/60000 (88%)]\tLoss: 0.237475\n",
            "Train Epoch: 7 [55000/60000 (92%)]\tLoss: 0.230967\n",
            "Train Epoch: 7 [57500/60000 (96%)]\tLoss: 0.146448\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 9826/10000 (98%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.146204\n",
            "Train Epoch: 8 [2500/60000 (4%)]\tLoss: 0.121888\n",
            "Train Epoch: 8 [5000/60000 (8%)]\tLoss: 0.116825\n",
            "Train Epoch: 8 [7500/60000 (12%)]\tLoss: 0.199824\n",
            "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 0.216804\n",
            "Train Epoch: 8 [12500/60000 (21%)]\tLoss: 0.288634\n",
            "Train Epoch: 8 [15000/60000 (25%)]\tLoss: 0.182770\n",
            "Train Epoch: 8 [17500/60000 (29%)]\tLoss: 0.112490\n",
            "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 0.161426\n",
            "Train Epoch: 8 [22500/60000 (38%)]\tLoss: 0.234685\n",
            "Train Epoch: 8 [25000/60000 (42%)]\tLoss: 0.112943\n",
            "Train Epoch: 8 [27500/60000 (46%)]\tLoss: 0.176609\n",
            "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 0.055921\n",
            "Train Epoch: 8 [32500/60000 (54%)]\tLoss: 0.186610\n",
            "Train Epoch: 8 [35000/60000 (58%)]\tLoss: 0.223910\n",
            "Train Epoch: 8 [37500/60000 (62%)]\tLoss: 0.113707\n",
            "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.146162\n",
            "Train Epoch: 8 [42500/60000 (71%)]\tLoss: 0.209407\n",
            "Train Epoch: 8 [45000/60000 (75%)]\tLoss: 0.116597\n",
            "Train Epoch: 8 [47500/60000 (79%)]\tLoss: 0.183569\n",
            "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 0.215562\n",
            "Train Epoch: 8 [52500/60000 (88%)]\tLoss: 0.264408\n",
            "Train Epoch: 8 [55000/60000 (92%)]\tLoss: 0.241545\n",
            "Train Epoch: 8 [57500/60000 (96%)]\tLoss: 0.295874\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 9828/10000 (98%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.140726\n",
            "Train Epoch: 9 [2500/60000 (4%)]\tLoss: 0.143706\n",
            "Train Epoch: 9 [5000/60000 (8%)]\tLoss: 0.130259\n",
            "Train Epoch: 9 [7500/60000 (12%)]\tLoss: 0.177964\n",
            "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 0.220538\n",
            "Train Epoch: 9 [12500/60000 (21%)]\tLoss: 0.161297\n",
            "Train Epoch: 9 [15000/60000 (25%)]\tLoss: 0.106748\n",
            "Train Epoch: 9 [17500/60000 (29%)]\tLoss: 0.118280\n",
            "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 0.260971\n",
            "Train Epoch: 9 [22500/60000 (38%)]\tLoss: 0.080340\n",
            "Train Epoch: 9 [25000/60000 (42%)]\tLoss: 0.149646\n",
            "Train Epoch: 9 [27500/60000 (46%)]\tLoss: 0.246838\n",
            "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 0.060852\n",
            "Train Epoch: 9 [32500/60000 (54%)]\tLoss: 0.145986\n",
            "Train Epoch: 9 [35000/60000 (58%)]\tLoss: 0.255339\n",
            "Train Epoch: 9 [37500/60000 (62%)]\tLoss: 0.096709\n",
            "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.116733\n",
            "Train Epoch: 9 [42500/60000 (71%)]\tLoss: 0.153015\n",
            "Train Epoch: 9 [45000/60000 (75%)]\tLoss: 0.154570\n",
            "Train Epoch: 9 [47500/60000 (79%)]\tLoss: 0.238364\n",
            "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 0.195187\n",
            "Train Epoch: 9 [52500/60000 (88%)]\tLoss: 0.151240\n",
            "Train Epoch: 9 [55000/60000 (92%)]\tLoss: 0.088239\n",
            "Train Epoch: 9 [57500/60000 (96%)]\tLoss: 0.227271\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 9838/10000 (98%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.103860\n",
            "Train Epoch: 10 [2500/60000 (4%)]\tLoss: 0.085570\n",
            "Train Epoch: 10 [5000/60000 (8%)]\tLoss: 0.119309\n",
            "Train Epoch: 10 [7500/60000 (12%)]\tLoss: 0.071651\n",
            "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 0.130809\n",
            "Train Epoch: 10 [12500/60000 (21%)]\tLoss: 0.158272\n",
            "Train Epoch: 10 [15000/60000 (25%)]\tLoss: 0.327125\n",
            "Train Epoch: 10 [17500/60000 (29%)]\tLoss: 0.134190\n",
            "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 0.057141\n",
            "Train Epoch: 10 [22500/60000 (38%)]\tLoss: 0.293734\n",
            "Train Epoch: 10 [25000/60000 (42%)]\tLoss: 0.152292\n",
            "Train Epoch: 10 [27500/60000 (46%)]\tLoss: 0.093784\n",
            "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 0.125892\n",
            "Train Epoch: 10 [32500/60000 (54%)]\tLoss: 0.081924\n",
            "Train Epoch: 10 [35000/60000 (58%)]\tLoss: 0.317244\n",
            "Train Epoch: 10 [37500/60000 (62%)]\tLoss: 0.214830\n",
            "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 0.105117\n",
            "Train Epoch: 10 [42500/60000 (71%)]\tLoss: 0.359786\n",
            "Train Epoch: 10 [45000/60000 (75%)]\tLoss: 0.203626\n",
            "Train Epoch: 10 [47500/60000 (79%)]\tLoss: 0.204267\n",
            "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 0.201817\n",
            "Train Epoch: 10 [52500/60000 (88%)]\tLoss: 0.137653\n",
            "Train Epoch: 10 [55000/60000 (92%)]\tLoss: 0.132829\n",
            "Train Epoch: 10 [57500/60000 (96%)]\tLoss: 0.154266\n",
            "\n",
            "Test set: Average loss: 0.0005, Accuracy: 9853/10000 (99%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(1, 11):\n",
        "  train(epoch)\n",
        "  test()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyOYmfluE56lqVlF5z3oLAqB",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
